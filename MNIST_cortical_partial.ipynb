{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "authorship_tag": "ABX9TyNWiTotQFY+/Ej14adSpKIZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zmarquis13/cortical_model_MNIST/blob/main/MNIST_cortical_partial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "jieD6EIVLH9H"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "\n",
        "test_data = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")"
      ],
      "metadata": {
        "id": "FJrRcI1cLUyQ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.1\n",
        "batch_size = 64\n",
        "epochs = 10"
      ],
      "metadata": {
        "id": "4zquxZNe6hbE"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataloader = DataLoader(training_data, batch_size, shuffle=True)\n",
        "test_dataloader = DataLoader(test_data, batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "71AIRkdGR3AR"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display image and label.\n",
        "train_features, train_labels = next(iter(train_dataloader))\n",
        "print(f\"Feature batch shape: {train_features.size()}\")\n",
        "print(f\"Labels batch shape: {train_labels.size()}\")\n",
        "img = train_features[0].squeeze()\n",
        "label = train_labels[0]\n",
        "plt.imshow(img, cmap=\"gray\")\n",
        "plt.show()\n",
        "print(f\"Label: {label}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "id": "q8tkOvQORp-J",
        "outputId": "eb9720ce-47b5-48fa-b140-da7206642493"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature batch shape: torch.Size([64, 1, 28, 28])\n",
            "Labels batch shape: torch.Size([64])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "jvLxBZk7Or_f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dev = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ],
      "metadata": {
        "id": "yx2b_8HNNSSW"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        #input layer\n",
        "        self.input = nn.Linear(28*28, 512)\n",
        "        self.hidden = nn.Linear(512, 512)\n",
        "\n",
        "        #cortex hidden layers\n",
        "        self.cortex0 = nn.Linear(512, 10)\n",
        "        self.cortex1 = nn.Linear(512, 10)\n",
        "        self.cortex2 = nn.Linear(512, 10)\n",
        "        self.cortex3 = nn.Linear(512, 10)\n",
        "        self.cortex4 = nn.Linear(512, 10)\n",
        "\n",
        "\n",
        "\n",
        "        #outputs for specific numbers\n",
        "        self.output0 = nn.Linear(10, 1)\n",
        "        self.output1 = nn.Linear(10, 1)\n",
        "        self.output2 = nn.Linear(10, 1)\n",
        "        self.output3 = nn.Linear(10, 1)\n",
        "        self.output4 = nn.Linear(10, 1)\n",
        "\n",
        "        #ouput for \"I don't know\"\n",
        "        self.output5 = nn.Linear(10, 1)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.input(x)\n",
        "        x = self.hidden(x)\n",
        "\n",
        "        x0 = torch.relu(self.cortex0(x))\n",
        "        x1 = torch.relu(self.cortex1(x))\n",
        "        x2 = torch.relu(self.cortex2(x))\n",
        "        x3 = torch.relu(self.cortex3(x))\n",
        "        x4 = torch.relu(self.cortex4(x))\n",
        "\n",
        "        x0 = self.output0(x0)\n",
        "        x1 = self.output1(x1)\n",
        "        x2 = self.output2(x2)\n",
        "        x3 = self.output3(x3)\n",
        "        x4 = self.output4(x4)\n",
        "\n",
        "\n",
        "        x = torch.cat((x0, x1, x2, x3, x4), 1)\n",
        "\n",
        "        #the value for the \"unsure\" output is 1 - sigmoid(sum(outputs 0-4))\n",
        "        temp = torch.ones(x.size(0), 1)\n",
        "        for i in range (x.size(0)):\n",
        "          sum = 0\n",
        "          for j in range(5):\n",
        "            sum += x[1][j]\n",
        "            temp[i] = 1 - torch.sigmoid(sum)\n",
        "\n",
        "        zeros = torch.zeros(x.size(0), 4)\n",
        "        intermediate = torch.cat((temp, zeros), 1)\n",
        "\n",
        "        x = torch.cat((x, intermediate), 1)\n",
        "\n",
        "        return x\n",
        "\n",
        "model = NeuralNetwork()"
      ],
      "metadata": {
        "id": "2vN0HUYENdif"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# something to consider: data is 50% \"null\" and 10% of each of the classified numbers, may cause bias\n",
        "# towards null but this is solvable by only including 1/6 of the null values\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n"
      ],
      "metadata": {
        "id": "YsmfJWL5NeYo"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "\n",
        "    # set model to train\n",
        "\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "\n",
        "        X = X.view(X.shape[0],784)\n",
        "\n",
        "        #generate prediction\n",
        "        pred = model(X)\n",
        "\n",
        "        # for all ground truths greater than 5, make them 5 (the \"I don't know value\")\n",
        "        for i in range(y.size(0)):\n",
        "              if y[i] > 5:\n",
        "                y[i] = 5\n",
        "\n",
        "        #calculate loss\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        #print loss every 100 batches\n",
        "        if batch % 100 == 99:\n",
        "            loss, current = loss.item(), batch * batch_size + len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "\n",
        "def test_loop(dataloader, model, loss_fn):\n",
        "\n",
        "    # set model to eval\n",
        "    model.eval()\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    test_loss, correct = 0, 0\n",
        "\n",
        "    #disable gradient calculation\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X = X.view(X.shape[0],784)\n",
        "\n",
        "            pred = model(X)\n",
        "\n",
        "            #for all ground truths greater than 5, make them 5 (the \"I don't know value\")\n",
        "            for i in range(y.size(0)):\n",
        "              if y[i] > 5:\n",
        "                y[i] = 5\n",
        "\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Number Test Results: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ],
      "metadata": {
        "id": "DNGpctX9Xonc"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_static(mode, loss_fn):\n",
        "  model.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    #size of about 10000 (10048)\n",
        "    size = 157*64\n",
        "    num_batches = 157\n",
        "    test_loss, correct = 0, 0\n",
        "\n",
        "    for i in range (num_batches):\n",
        "\n",
        "      static = torch.rand(64, 784)\n",
        "      pred = model(static)\n",
        "\n",
        "      #set all labels to 5 (it's static so an \"I don't know\" is accurate)\n",
        "      y = torch.ones(64, dtype=torch.long)\n",
        "      y = y * 5\n",
        "\n",
        "      test_loss += loss_fn(pred, y).item()\n",
        "      correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "  test_loss /= num_batches\n",
        "\n",
        "  correct /= 10048.0\n",
        "  print(f\"Static Test Results: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "\n"
      ],
      "metadata": {
        "id": "CMqtJMmbbEAu"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
        "\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
        "    test_loop(test_dataloader, model, loss_fn)\n",
        "    test_static(model, loss_fn)\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98F0IYYJXpvX",
        "outputId": "d83cc447-f21a-45a4-eba6-8cca0a8f8fde"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 1.009162  [ 6400/60000]\n",
            "loss: 1.033860  [12800/60000]\n",
            "loss: 0.821061  [19200/60000]\n",
            "loss: 0.604388  [25600/60000]\n",
            "loss: 0.783856  [32000/60000]\n",
            "loss: 0.935323  [38400/60000]\n",
            "loss: 0.872530  [44800/60000]\n",
            "loss: 0.709434  [51200/60000]\n",
            "loss: 1.003004  [57600/60000]\n",
            "Number Test Results: \n",
            " Accuracy: 93.4%, Avg loss: 0.662800 \n",
            "\n",
            "Static Test Results: \n",
            " Accuracy: 100.0%, Avg loss: 0.917881 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 0.587298  [ 6400/60000]\n",
            "loss: 0.592821  [12800/60000]\n",
            "loss: 0.757221  [19200/60000]\n",
            "loss: 0.621650  [25600/60000]\n",
            "loss: 0.762383  [32000/60000]\n",
            "loss: 0.703448  [38400/60000]\n",
            "loss: 0.855439  [44800/60000]\n",
            "loss: 0.554001  [51200/60000]\n",
            "loss: 0.718895  [57600/60000]\n",
            "Number Test Results: \n",
            " Accuracy: 91.7%, Avg loss: 0.722258 \n",
            "\n",
            "Static Test Results: \n",
            " Accuracy: 88.3%, Avg loss: 1.055454 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 0.881703  [ 6400/60000]\n",
            "loss: 0.587773  [12800/60000]\n",
            "loss: 0.751596  [19200/60000]\n",
            "loss: 0.685362  [25600/60000]\n",
            "loss: 0.633028  [32000/60000]\n",
            "loss: 0.543800  [38400/60000]\n",
            "loss: 0.552037  [44800/60000]\n",
            "loss: 0.577691  [51200/60000]\n",
            "loss: 0.598893  [57600/60000]\n",
            "Number Test Results: \n",
            " Accuracy: 93.6%, Avg loss: 0.626193 \n",
            "\n",
            "Static Test Results: \n",
            " Accuracy: 34.8%, Avg loss: 1.677382 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 0.703189  [ 6400/60000]\n",
            "loss: 0.534985  [12800/60000]\n",
            "loss: 0.628780  [19200/60000]\n",
            "loss: 0.473654  [25600/60000]\n",
            "loss: 0.498627  [32000/60000]\n",
            "loss: 0.740232  [38400/60000]\n",
            "loss: 0.611761  [44800/60000]\n",
            "loss: 0.645147  [51200/60000]\n",
            "loss: 0.580174  [57600/60000]\n",
            "Number Test Results: \n",
            " Accuracy: 94.3%, Avg loss: 0.597604 \n",
            "\n",
            "Static Test Results: \n",
            " Accuracy: 65.2%, Avg loss: 1.243486 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 0.514391  [ 6400/60000]\n",
            "loss: 0.645979  [12800/60000]\n",
            "loss: 0.642194  [19200/60000]\n",
            "loss: 0.634095  [25600/60000]\n",
            "loss: 0.481382  [32000/60000]\n",
            "loss: 0.520671  [38400/60000]\n",
            "loss: 0.638922  [44800/60000]\n",
            "loss: 0.587868  [51200/60000]\n",
            "loss: 0.574252  [57600/60000]\n",
            "Number Test Results: \n",
            " Accuracy: 95.1%, Avg loss: 0.576139 \n",
            "\n",
            "Static Test Results: \n",
            " Accuracy: 93.7%, Avg loss: 1.024635 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 0.690330  [ 6400/60000]\n",
            "loss: 0.494300  [12800/60000]\n",
            "loss: 0.580270  [19200/60000]\n",
            "loss: 0.655200  [25600/60000]\n",
            "loss: 0.604658  [32000/60000]\n",
            "loss: 0.463521  [38400/60000]\n",
            "loss: 0.726980  [44800/60000]\n",
            "loss: 0.514486  [51200/60000]\n",
            "loss: 0.490707  [57600/60000]\n",
            "Number Test Results: \n",
            " Accuracy: 95.7%, Avg loss: 0.566580 \n",
            "\n",
            "Static Test Results: \n",
            " Accuracy: 87.8%, Avg loss: 1.055388 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 0.472067  [ 6400/60000]\n",
            "loss: 0.588426  [12800/60000]\n",
            "loss: 0.699940  [19200/60000]\n",
            "loss: 0.481114  [25600/60000]\n",
            "loss: 0.639947  [32000/60000]\n",
            "loss: 0.648825  [38400/60000]\n",
            "loss: 0.396013  [44800/60000]\n",
            "loss: 0.586940  [51200/60000]\n",
            "loss: 0.529122  [57600/60000]\n",
            "Number Test Results: \n",
            " Accuracy: 94.5%, Avg loss: 0.575564 \n",
            "\n",
            "Static Test Results: \n",
            " Accuracy: 40.7%, Avg loss: 1.449088 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 0.504298  [ 6400/60000]\n",
            "loss: 0.532692  [12800/60000]\n",
            "loss: 0.593737  [19200/60000]\n",
            "loss: 0.488768  [25600/60000]\n",
            "loss: 0.628466  [32000/60000]\n",
            "loss: 0.540206  [38400/60000]\n",
            "loss: 0.588343  [44800/60000]\n",
            "loss: 0.541535  [51200/60000]\n",
            "loss: 0.602875  [57600/60000]\n",
            "Number Test Results: \n",
            " Accuracy: 96.2%, Avg loss: 0.558618 \n",
            "\n",
            "Static Test Results: \n",
            " Accuracy: 98.1%, Avg loss: 0.953366 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 0.621448  [ 6400/60000]\n",
            "loss: 0.558797  [12800/60000]\n",
            "loss: 0.478769  [19200/60000]\n",
            "loss: 0.559323  [25600/60000]\n",
            "loss: 0.694719  [32000/60000]\n",
            "loss: 0.594715  [38400/60000]\n",
            "loss: 0.503794  [44800/60000]\n",
            "loss: 0.552671  [51200/60000]\n",
            "loss: 0.825209  [57600/60000]\n",
            "Number Test Results: \n",
            " Accuracy: 95.9%, Avg loss: 0.548415 \n",
            "\n",
            "Static Test Results: \n",
            " Accuracy: 13.7%, Avg loss: 2.201542 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 0.628798  [ 6400/60000]\n",
            "loss: 0.538019  [12800/60000]\n",
            "loss: 0.666707  [19200/60000]\n",
            "loss: 0.496068  [25600/60000]\n",
            "loss: 0.568848  [32000/60000]\n",
            "loss: 0.647345  [38400/60000]\n",
            "loss: 0.531498  [44800/60000]\n",
            "loss: 0.640451  [51200/60000]\n",
            "loss: 0.574314  [57600/60000]\n",
            "Number Test Results: \n",
            " Accuracy: 95.1%, Avg loss: 0.564235 \n",
            "\n",
            "Static Test Results: \n",
            " Accuracy: 88.3%, Avg loss: 1.038662 \n",
            "\n",
            "Done!\n"
          ]
        }
      ]
    }
  ]
}